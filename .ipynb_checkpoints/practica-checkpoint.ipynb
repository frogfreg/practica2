{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alumno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(stopwords.words('spanish'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw01 = \"Paren esta masacre. Por favor.\"\n",
    "tw02 = \"Bro ya no quiero ir a cursos tengo mucha flojera para funcionar\"\n",
    "tw03 = \"Wey qué pedo con las personas que dicen que Diego Santoy está guapo. Asesino a unos niños\"\n",
    "tw04 = \"Ayer me escale el pelo y soy un mocho\"\n",
    "tw05 = \"Yo no se si darle otra oportunidad a full metal alchemist, siento que no estoy viendo algo que todos si\"\n",
    "tw06 = \"Casi te hago papá y ya ni saludas hdtpm\"\n",
    "tw07 = \"No con cualquiera se habla de todo\"\n",
    "tw08 = \"El mejor placer en la vida es hacer lo que la gente te dice que no puedes hacer\"\n",
    "tw09 = \"Me he despertado de un susto al ver la matanza que ha deducido hacer mi cuerpo y bueno por lo menos he madrugado más\"\n",
    "tw10 = \"Un año después del juicio a el 'Chapo' Guzman, todo está igual, el cártel intacto, la corrupción también\"\n",
    "tw11 = \"full metal alchemist brotherhood está sobrevalorado pero ustedes no están listos para esa conversación\"\n",
    "tw12 = \"Este mercurio en gatorade me está afectando demasiado\"\n",
    "tw13 = \"tienes tantas de coger que no leiste ganas\"\n",
    "tw14 = \"no puedo creer que mi yo de 13 años se depiló la pucha para el concierto de one direction porque genuinamente crei que iba a pasar algo ptm\"\n",
    "tw15 = \"mi terapeuta recordandome que valgo mucho que no debo ser duro conmigo mismo\"\n",
    "tw16 = \"Amigas feministas, ya podemos manifestarnos como queramos porque Luis ya nos dió permiso. Venga, ya sólo nos faltaba la aprobación de un hombre más\"\n",
    "tw17 = \"Yo fui de los que hace meses criticó que las mujeres rayaran y vandalizaran monumentos. Después de ver las respuestas de hoy del presidente, estoy totalmente arrepentido y avergonzado.\"\n",
    "tw18 = \"Llorando de coraje por todas las que no están\"\n",
    "tw19 = \"ok pero la animación de naruto vs orochimaru cuando estaban en el examen... i gasped\"\n",
    "tw20 = \"que huevotes los tuyos de romperme el corazón a mi\"\n",
    "tw21 = \"Mirense beastars es tan bueno que te vuelves furry\"\n",
    "tw22 = \"no peleen por anime\"\n",
    "tw23 = \"El Atlas es un 'equipito'\"\n",
    "tw24 = \"Usain bolt tiene una gorra del Cruz Azul\"\n",
    "tw25 = \"En México te matan por ejercer tu derecho a la libertad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [tw01, tw02,tw03,tw04,tw05,tw06,tw07,tw08,tw09,tw10,tw11,tw12,tw13,tw14,tw15,tw16,tw17,tw18,tw19,tw20,tw21,tw22,tw23,tw24,tw25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paren', 'esta', 'masacre', 'por', 'favor']\n"
     ]
    }
   ],
   "source": [
    "tweet_01_tokens = tokenizer.tokenize(tweets[0].lower())\n",
    "print(tweet_01_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paren', 'masacre', 'favor']\n"
     ]
    }
   ],
   "source": [
    "tweet_01_tokens_wout_stopwords = []\n",
    "for word in tweet_01_tokens:\n",
    "    if word not in stopwords.words('spanish'): tweet_01_tokens_wout_stopwords.append(word)\n",
    "print(tweet_01_tokens_wout_stopwords)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['paren', 'esta', 'masacre', 'por', 'favor'], ['bro', 'ya', 'no', 'quiero', 'ir', 'a', 'cursos', 'tengo', 'mucha', 'flojera', 'para', 'funcionar'], ['wey', 'qué', 'pedo', 'con', 'las', 'personas', 'que', 'dicen', 'que', 'diego', 'santoy', 'está', 'guapo', 'asesino', 'a', 'unos', 'niños'], ['ayer', 'me', 'escale', 'el', 'pelo', 'y', 'soy', 'un', 'mocho'], ['yo', 'no', 'se', 'si', 'darle', 'otra', 'oportunidad', 'a', 'full', 'metal', 'alchemist', 'siento', 'que', 'no', 'estoy', 'viendo', 'algo', 'que', 'todos', 'si'], ['casi', 'te', 'hago', 'papá', 'y', 'ya', 'ni', 'saludas', 'hdtpm'], ['no', 'con', 'cualquiera', 'se', 'habla', 'de', 'todo'], ['el', 'mejor', 'placer', 'en', 'la', 'vida', 'es', 'hacer', 'lo', 'que', 'la', 'gente', 'te', 'dice', 'que', 'no', 'puedes', 'hacer'], ['me', 'he', 'despertado', 'de', 'un', 'susto', 'al', 'ver', 'la', 'matanza', 'que', 'ha', 'deducido', 'hacer', 'mi', 'cuerpo', 'y', 'bueno', 'por', 'lo', 'menos', 'he', 'madrugado', 'más'], ['un', 'año', 'después', 'del', 'juicio', 'a', 'el', 'chapo', 'guzman', 'todo', 'está', 'igual', 'el', 'cártel', 'intacto', 'la', 'corrupción', 'también'], ['full', 'metal', 'alchemist', 'brotherhood', 'está', 'sobrevalorado', 'pero', 'ustedes', 'no', 'están', 'listos', 'para', 'esa', 'conversación'], ['este', 'mercurio', 'en', 'gatorade', 'me', 'está', 'afectando', 'demasiado'], ['tienes', 'tantas', 'de', 'coger', 'que', 'no', 'leiste', 'ganas'], ['no', 'puedo', 'creer', 'que', 'mi', 'yo', 'de', '13', 'años', 'se', 'depiló', 'la', 'pucha', 'para', 'el', 'concierto', 'de', 'one', 'direction', 'porque', 'genuinamente', 'crei', 'que', 'iba', 'a', 'pasar', 'algo', 'ptm'], ['mi', 'terapeuta', 'recordandome', 'que', 'valgo', 'mucho', 'que', 'no', 'debo', 'ser', 'duro', 'conmigo', 'mismo'], ['amigas', 'feministas', 'ya', 'podemos', 'manifestarnos', 'como', 'queramos', 'porque', 'luis', 'ya', 'nos', 'dió', 'permiso', 'venga', 'ya', 'sólo', 'nos', 'faltaba', 'la', 'aprobación', 'de', 'un', 'hombre', 'más'], ['yo', 'fui', 'de', 'los', 'que', 'hace', 'meses', 'criticó', 'que', 'las', 'mujeres', 'rayaran', 'y', 'vandalizaran', 'monumentos', 'después', 'de', 'ver', 'las', 'respuestas', 'de', 'hoy', 'del', 'presidente', 'estoy', 'totalmente', 'arrepentido', 'y', 'avergonzado'], ['llorando', 'de', 'coraje', 'por', 'todas', 'las', 'que', 'no', 'están'], ['ok', 'pero', 'la', 'animación', 'de', 'naruto', 'vs', 'orochimaru', 'cuando', 'estaban', 'en', 'el', 'examen', 'i', 'gasped'], ['que', 'huevotes', 'los', 'tuyos', 'de', 'romperme', 'el', 'corazón', 'a', 'mi'], ['mirense', 'beastars', 'es', 'tan', 'bueno', 'que', 'te', 'vuelves', 'furry'], ['no', 'peleen', 'por', 'anime'], ['el', 'atlas', 'es', 'un', 'equipito'], ['usain', 'bolt', 'tiene', 'una', 'gorra', 'del', 'cruz', 'azul'], ['en', 'méxico', 'te', 'matan', 'por', 'ejercer', 'tu', 'derecho', 'a', 'la', 'libertad']]\n"
     ]
    }
   ],
   "source": [
    "tweets_tokens = []\n",
    "for tweet in tweets:\n",
    "        tweets_tokens.append(tokenizer.tokenize(tweet.lower()))\n",
    "print(tweets_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tokens_wout_stopwords = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
